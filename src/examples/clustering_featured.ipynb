{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering NIFTY Feature-Engineered Data\n",
    "\n",
    "This notebook demonstrates unsupervised clustering (K-Means) on the feature-engineered NIFTY dataset.\n",
    "\n",
    "- Data: `data/nifty/train/featured.csv`\n",
    "- Libraries: pandas, numpy, scikit-learn, matplotlib, seaborn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2. Load the feature-engineered data\n",
    "data_path = '../../data/nifty/train/featured.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(f'Loaded {len(df)} rows and {len(df.columns)} columns.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection for clustering\n",
    "\n",
    "We'll select a subset of features that are numeric and relevant for clustering.\n",
    "You can adjust this list based on your analysis goals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Select features for clustering\n",
    "features = [\n",
    "    'daily_return', 'log_return', 'price_range',\n",
    "    'ma_5', 'ma_20', 'volatility_5', 'volatility_20',\n",
    "    'rsi_14', 'macd_12_26', 'macd_signal_12_26', 'macd_histogram_12_26',\n",
    "    'stoch_14', 'stoch_smoothk', 'stoch_smoothd'\n",
    "]\n",
    "# Drop rows with missing values in selected features\n",
    "X = df[features].dropna().copy()\n",
    "print(f'Clustering on {X.shape[0]} rows and {X.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature scaling\n",
    "\n",
    "K-Means is sensitive to feature scale, so we standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the number of clusters (Elbow Method)\n",
    "\n",
    "We'll plot the inertia (within-cluster sum of squares) for different cluster counts."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "inertia = []\n",
    "K_range = range(2, 11)\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fit K-Means and assign clusters\n",
    "\n",
    "Choose the number of clusters based on the elbow plot above (e.g., k=3)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "k = 3  # Change this based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "df_clustered = df.loc[X.index].copy()\n",
    "df_clustered['cluster'] = clusters\n",
    "df_clustered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize clusters using PCA (2D plot)\n",
    "\n",
    "We'll use PCA to reduce the feature space to 2D for visualization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='Set2', alpha=0.7)\n",
    "plt.title('Clusters visualized with PCA')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cluster analysis\n",
    "\n",
    "Let's look at the mean values of each feature for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_clustered.groupby('cluster')[features].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can further analyze clusters, visualize time series by cluster, or use other clustering algorithms as needed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
