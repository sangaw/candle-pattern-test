{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIFTY Data Analysis Workflow\n",
    "\n",
    "This notebook demonstrates a comprehensive workflow for:\n",
    "1. Fetching NIFTY data for 2025 using Kite Connect API\n",
    "2. Saving the data as CSV\n",
    "3. Analyzing candlestick patterns\n",
    "4. Generating comprehensive reports\n",
    "\n",
    "The workflow uses Pydantic for data validation and orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, Any, List\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname('.'), '..'))\n",
    "\n",
    "from data_fetcher import KiteConnectDataFetcher\n",
    "from candlestick_patterns import CandlestickPatternAnalyzer\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workflow components\n",
    "data_fetcher = KiteConnectDataFetcher()\n",
    "pattern_analyzer = CandlestickPatternAnalyzer()\n",
    "\n",
    "# Ensure data directory exists\n",
    "data_dir = Path(\"../../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Components initialized successfully\")\n",
    "print(f\"üìÅ Data directory: {data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch NIFTY Data for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for 2025\n",
    "from_date = \"2025-01-01\"\n",
    "to_date = \"2025-12-31\"\n",
    "\n",
    "print(f\"üìä Fetching NIFTY data from {from_date} to {to_date}\")\n",
    "\n",
    "# Fetch historical data\n",
    "df = data_fetcher.get_historical_data(\n",
    "    from_date=from_date,\n",
    "    to_date=to_date,\n",
    "    interval='day'\n",
    ")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"‚ö†Ô∏è  No data fetched for the specified date range\")\n",
    "else:\n",
    "    print(f\"‚úÖ Successfully fetched {len(df)} daily candles\")\n",
    "    print(f\"üìÖ Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"üí∞ Price range: {df['low'].min():.2f} - {df['high'].max():.2f}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"nifty_daily_2025_{timestamp}.csv\"\n",
    "csv_path = data_dir / csv_filename\n",
    "\n",
    "# Ensure column names are correct\n",
    "if 'date' in df.columns:\n",
    "    df = df.rename(columns={\n",
    "        'date': 'Date',\n",
    "        'open': 'Open',\n",
    "        'high': 'High',\n",
    "        'low': 'Low',\n",
    "        'close': 'Close',\n",
    "        'volume': 'Volume'\n",
    "    })\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"üíæ Data saved to: {csv_path}\")\n",
    "print(f\"üìÅ File size: {csv_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Candlestick Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns\n",
    "print(\"üîç Analyzing candlestick patterns...\")\n",
    "df_with_patterns = pattern_analyzer.analyze_patterns(df)\n",
    "\n",
    "# Get pattern summary\n",
    "pattern_summary = pattern_analyzer.get_pattern_summary(df_with_patterns)\n",
    "\n",
    "print(f\"‚úÖ Pattern analysis completed for {len(df_with_patterns)} candles\")\n",
    "print(\"\\nüìä Pattern Summary:\")\n",
    "for pattern, count in pattern_summary.items():\n",
    "    if count > 0:\n",
    "        print(f\"  - {pattern}: {count} occurrences\")\n",
    "\n",
    "# Display rows with patterns\n",
    "pattern_rows = df_with_patterns[df_with_patterns['pattern'] != '']\n",
    "if not pattern_rows.empty:\n",
    "    print(f\"\\nüéØ Found {len(pattern_rows)} candles with patterns:\")\n",
    "    display(pattern_rows[['Date', 'Open', 'High', 'Low', 'Close', 'pattern']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Pattern Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pattern dates for each pattern type\n",
    "pattern_dates = {}\n",
    "for pattern_name in pattern_summary.keys():\n",
    "    dates = pattern_analyzer.get_pattern_dates(df_with_patterns, pattern_name)\n",
    "    pattern_dates[pattern_name] = dates\n",
    "\n",
    "# Save results\n",
    "output_filename = f\"nifty_pattern_analysis_{timestamp}.csv\"\n",
    "output_path = data_dir / output_filename\n",
    "df_with_patterns.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"üíæ Pattern analysis results saved to: {output_path}\")\n",
    "\n",
    "# Generate comprehensive summary\n",
    "total_patterns = sum(pattern_summary.values())\n",
    "total_candles = len(df_with_patterns)\n",
    "pattern_percentage = (total_patterns / total_candles * 100) if total_candles > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NIFTY CANDLESTICK PATTERN ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total candles analyzed: {total_candles}\")\n",
    "print(f\"Total patterns found: {total_patterns}\")\n",
    "print(f\"Pattern occurrence rate: {pattern_percentage:.2f}%\")\n",
    "print(\"\\nPattern Breakdown:\")\n",
    "\n",
    "for pattern, count in pattern_summary.items():\n",
    "    if count > 0:\n",
    "        print(f\"- {pattern}: {count} occurrences\")\n",
    "        if pattern in pattern_dates and pattern_dates[pattern]:\n",
    "            print(f\"  Dates: {', '.join(pattern_dates[pattern][:5])}\")\n",
    "            if len(pattern_dates[pattern]) > 5:\n",
    "                print(f\"  ... and {len(pattern_dates[pattern]) - 5} more\")\n",
    "\n",
    "# Price movement analysis\n",
    "if not df.empty:\n",
    "    price_change = df['Close'].iloc[-1] - df['Close'].iloc[0]\n",
    "    price_change_pct = (price_change / df['Close'].iloc[0]) * 100\n",
    "    print(f\"\\nPrice Movement Analysis:\")\n",
    "    print(f\"- Start price: {df['Close'].iloc[0]:.2f}\")\n",
    "    print(f\"- End price: {df['Close'].iloc[-1]:.2f}\")\n",
    "    print(f\"- Total change: {price_change:.2f} ({price_change_pct:+.2f}%)\")\n",
    "    print(f\"- Highest price: {df['High'].max():.2f}\")\n",
    "    print(f\"- Lowest price: {df['Low'].min():.2f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Price chart with patterns\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df['Date'], df['Close'], label='Close Price', linewidth=2)\n",
    "ax1.set_title('NIFTY Close Price (2025)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Pattern distribution\n",
    "ax2 = axes[0, 1]\n",
    "patterns_with_counts = {k: v for k, v in pattern_summary.items() if v > 0}\n",
    "if patterns_with_counts:\n",
    "    ax2.bar(patterns_with_counts.keys(), patterns_with_counts.values(), color='skyblue')\n",
    "    ax2.set_title('Pattern Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Pattern Type')\n",
    "    ax2.set_ylabel('Count')\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# 3. Volume analysis\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(df['Date'], df['Volume'], alpha=0.7, color='lightgreen')\n",
    "ax3.set_title('Trading Volume', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Volume')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Price range (High-Low)\n",
    "ax4 = axes[1, 1]\n",
    "price_range = df['High'] - df['Low']\n",
    "ax4.plot(df['Date'], price_range, color='orange', linewidth=2)\n",
    "ax4.set_title('Daily Price Range (High - Low)', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Price Range')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ NIFTY Data Analysis Workflow Completed Successfully!\")\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(f\"  - Raw data: {csv_path}\")\n",
    "print(f\"  - Pattern analysis: {output_path}\")\n",
    "print(\"\\nüìä Key Insights:\")\n",
    "print(f\"  - Analyzed {len(df)} daily candles\")\n",
    "print(f\"  - Found {sum(pattern_summary.values())} candlestick patterns\")\n",
    "print(f\"  - Pattern occurrence rate: {(sum(pattern_summary.values()) / len(df) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  - Review specific pattern dates for trading signals\")\n",
    "print(\"  - Analyze pattern effectiveness in different market conditions\")\n",
    "print(\"  - Extend analysis to other timeframes (hourly, weekly)\")\n",
    "print(\"  - Integrate with additional technical indicators\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
