{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIFTY Data Analysis Workflow\n",
    "\n",
    "This notebook demonstrates a comprehensive workflow for:\n",
    "1. Fetching NIFTY data for 2025 using Kite Connect API\n",
    "2. Saving the data as CSV\n",
    "3. Analyzing candlestick patterns\n",
    "4. Generating comprehensive reports\n",
    "\n",
    "The workflow uses Pydantic for data validation and orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, Any, List\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname('.'), '..'))\n",
    "\n",
    "from data_fetcher import KiteConnectDataFetcher\n",
    "from candlestick_patterns import CandlestickPatternAnalyzer\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workflow components\n",
    "data_fetcher = KiteConnectDataFetcher()\n",
    "pattern_analyzer = CandlestickPatternAnalyzer()\n",
    "\n",
    "# Ensure data directory exists\n",
    "data_dir = Path(\"../../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✅ Components initialized successfully\")\n",
    "print(f\"📁 Data directory: {data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fetch NIFTY Data for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for 2025\n",
    "from_date = \"2025-01-01\"\n",
    "to_date = \"2025-12-31\"\n",
    "\n",
    "print(f\"📊 Fetching NIFTY data from {from_date} to {to_date}\")\n",
    "\n",
    "# Fetch historical data\n",
    "df = data_fetcher.get_historical_data(\n",
    "    from_date=from_date,\n",
    "    to_date=to_date,\n",
    "    interval='day'\n",
    ")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"⚠️  No data fetched for the specified date range\")\n",
    "else:\n",
    "    print(f\"✅ Successfully fetched {len(df)} daily candles\")\n",
    "    print(f\"📅 Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"💰 Price range: {df['low'].min():.2f} - {df['high'].max():.2f}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save Data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"nifty_daily_2025_{timestamp}.csv\"\n",
    "csv_path = data_dir / csv_filename\n",
    "\n",
    "# Ensure column names are correct\n",
    "if 'date' in df.columns:\n",
    "    df = df.rename(columns={\n",
    "        'date': 'Date',\n",
    "        'open': 'Open',\n",
    "        'high': 'High',\n",
    "        'low': 'Low',\n",
    "        'close': 'Close',\n",
    "        'volume': 'Volume'\n",
    "    })\n",
    "\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"💾 Data saved to: {csv_path}\")\n",
    "print(f\"📁 File size: {csv_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Candlestick Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns\n",
    "print(\"🔍 Analyzing candlestick patterns...\")\n",
    "df_with_patterns = pattern_analyzer.analyze_patterns(df)\n",
    "\n",
    "# Get pattern summary\n",
    "pattern_summary = pattern_analyzer.get_pattern_summary(df_with_patterns)\n",
    "\n",
    "print(f\"✅ Pattern analysis completed for {len(df_with_patterns)} candles\")\n",
    "print(\"\\n📊 Pattern Summary:\")\n",
    "for pattern, count in pattern_summary.items():\n",
    "    if count > 0:\n",
    "        print(f\"  - {pattern}: {count} occurrences\")\n",
    "\n",
    "# Display rows with patterns\n",
    "pattern_rows = df_with_patterns[df_with_patterns['pattern'] != '']\n",
    "if not pattern_rows.empty:\n",
    "    print(f\"\\n🎯 Found {len(pattern_rows)} candles with patterns:\")\n",
    "    display(pattern_rows[['Date', 'Open', 'High', 'Low', 'Close', 'pattern']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Pattern Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pattern dates for each pattern type\n",
    "pattern_dates = {}\n",
    "for pattern_name in pattern_summary.keys():\n",
    "    dates = pattern_analyzer.get_pattern_dates(df_with_patterns, pattern_name)\n",
    "    pattern_dates[pattern_name] = dates\n",
    "\n",
    "# Save results\n",
    "output_filename = f\"nifty_pattern_analysis_{timestamp}.csv\"\n",
    "output_path = data_dir / output_filename\n",
    "df_with_patterns.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"💾 Pattern analysis results saved to: {output_path}\")\n",
    "\n",
    "# Generate comprehensive summary\n",
    "total_patterns = sum(pattern_summary.values())\n",
    "total_candles = len(df_with_patterns)\n",
    "pattern_percentage = (total_patterns / total_candles * 100) if total_candles > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NIFTY CANDLESTICK PATTERN ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total candles analyzed: {total_candles}\")\n",
    "print(f\"Total patterns found: {total_patterns}\")\n",
    "print(f\"Pattern occurrence rate: {pattern_percentage:.2f}%\")\n",
    "print(\"\\nPattern Breakdown:\")\n",
    "\n",
    "for pattern, count in pattern_summary.items():\n",
    "    if count > 0:\n",
    "        print(f\"- {pattern}: {count} occurrences\")\n",
    "        if pattern in pattern_dates and pattern_dates[pattern]:\n",
    "            print(f\"  Dates: {', '.join(pattern_dates[pattern][:5])}\")\n",
    "            if len(pattern_dates[pattern]) > 5:\n",
    "                print(f\"  ... and {len(pattern_dates[pattern]) - 5} more\")\n",
    "\n",
    "# Price movement analysis\n",
    "if not df.empty:\n",
    "    price_change = df['Close'].iloc[-1] - df['Close'].iloc[0]\n",
    "    price_change_pct = (price_change / df['Close'].iloc[0]) * 100\n",
    "    print(f\"\\nPrice Movement Analysis:\")\n",
    "    print(f\"- Start price: {df['Close'].iloc[0]:.2f}\")\n",
    "    print(f\"- End price: {df['Close'].iloc[-1]:.2f}\")\n",
    "    print(f\"- Total change: {price_change:.2f} ({price_change_pct:+.2f}%)\")\n",
    "    print(f\"- Highest price: {df['High'].max():.2f}\")\n",
    "    print(f\"- Lowest price: {df['Low'].min():.2f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Price chart with patterns\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df['Date'], df['Close'], label='Close Price', linewidth=2)\n",
    "ax1.set_title('NIFTY Close Price (2025)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Pattern distribution\n",
    "ax2 = axes[0, 1]\n",
    "patterns_with_counts = {k: v for k, v in pattern_summary.items() if v > 0}\n",
    "if patterns_with_counts:\n",
    "    ax2.bar(patterns_with_counts.keys(), patterns_with_counts.values(), color='skyblue')\n",
    "    ax2.set_title('Pattern Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Pattern Type')\n",
    "    ax2.set_ylabel('Count')\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# 3. Volume analysis\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(df['Date'], df['Volume'], alpha=0.7, color='lightgreen')\n",
    "ax3.set_title('Trading Volume', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Volume')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Price range (High-Low)\n",
    "ax4 = axes[1, 1]\n",
    "price_range = df['High'] - df['Low']\n",
    "ax4.plot(df['Date'], price_range, color='orange', linewidth=2)\n",
    "ax4.set_title('Daily Price Range (High - Low)', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Price Range')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 NIFTY Data Analysis Workflow Completed Successfully!\")\n",
    "print(\"\\n📁 Generated Files:\")\n",
    "print(f\"  - Raw data: {csv_path}\")\n",
    "print(f\"  - Pattern analysis: {output_path}\")\n",
    "print(\"\\n📊 Key Insights:\")\n",
    "print(f\"  - Analyzed {len(df)} daily candles\")\n",
    "print(f\"  - Found {sum(pattern_summary.values())} candlestick patterns\")\n",
    "print(f\"  - Pattern occurrence rate: {(sum(pattern_summary.values()) / len(df) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"  - Review specific pattern dates for trading signals\")\n",
    "print(\"  - Analyze pattern effectiveness in different market conditions\")\n",
    "print(\"  - Extend analysis to other timeframes (hourly, weekly)\")\n",
    "print(\"  - Integrate with additional technical indicators\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
